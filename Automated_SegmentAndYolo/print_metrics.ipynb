{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f439d446",
   "metadata": {},
   "source": [
    "# Print Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f39c31",
   "metadata": {},
   "source": [
    "## Creating Required Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4380a4",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9cc21d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07427de3",
   "metadata": {},
   "source": [
    "### Function to Find the Best YOLO Model (best.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7608373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_dir='runs_yolo/'):\n",
    "    best_paths = list(Path(base_dir).rglob('best.pt'))\n",
    "    if not best_paths:\n",
    "        raise FileNotFoundError(\"No 'best.pt' file found in the 'runs/' directory.\")\n",
    "    \n",
    "    # Optionally, sort by latest modified time\n",
    "    best_paths.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    print(f\"[+] Found best.pt at: {best_paths[0]}\")\n",
    "    return str(best_paths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d57524",
   "metadata": {},
   "source": [
    "### Functions to Load and Print Metrics from YOLO Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1f287ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_results_csv(directory):\n",
    "    \"\"\"Find the results.csv file in the specified directory.\"\"\"\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if 'results.csv' in files:\n",
    "            return os.path.join(root, 'results.csv')\n",
    "    return None\n",
    "\n",
    "def load_results_csv(results_csv_path):\n",
    "    \"\"\"Load the results CSV into a pandas DataFrame.\"\"\"\n",
    "    return pd.read_csv(results_csv_path)\n",
    "\n",
    "def calculate_total_epochs(df):\n",
    "    \"\"\"Calculate the total number of epochs from the DataFrame.\"\"\"\n",
    "    return df['epoch'].max()\n",
    "\n",
    "def calculate_training_loss(epoch_data):\n",
    "    \"\"\"Calculate the total training loss from the given epoch data.\"\"\"\n",
    "    train_box_loss = epoch_data['train/box_loss']\n",
    "    train_cls_loss = epoch_data['train/cls_loss']\n",
    "    train_dfl_loss = epoch_data['train/dfl_loss']\n",
    "    return train_box_loss + train_cls_loss + train_dfl_loss\n",
    "\n",
    "def calculate_validation_loss(epoch_data):\n",
    "    \"\"\"Calculate the total validation loss from the given epoch data.\"\"\"\n",
    "    val_box_loss = epoch_data['val/box_loss']\n",
    "    val_cls_loss = epoch_data['val/cls_loss']\n",
    "    val_dfl_loss = epoch_data['val/dfl_loss']\n",
    "    return val_box_loss + val_cls_loss + val_dfl_loss\n",
    "\n",
    "def print_final_metrics(df):\n",
    "    \"\"\"Print the final metrics for the last epoch.\"\"\"\n",
    "    final_epoch_data = df.iloc[-1]\n",
    "\n",
    "    # Calculate total training and validation loss\n",
    "    train_loss = calculate_training_loss(final_epoch_data)\n",
    "    val_loss = calculate_validation_loss(final_epoch_data)\n",
    "\n",
    "    # Print overall metrics\n",
    "    print(\"\\n========== Final Training Metrics ==========\")\n",
    "    print(f\"Training Loss: {train_loss:.6f}\")\n",
    "    print(f\"Precision: {final_epoch_data['metrics/precision(B)']:.6f}\")\n",
    "    print(f\"Recall: {final_epoch_data['metrics/recall(B)']:.6f}\")\n",
    "    print(f\"mAP@0.5: {final_epoch_data['metrics/mAP50(B)']:.6f}\")\n",
    "    print(f\"mAP@0.5:0.95: {final_epoch_data['metrics/mAP50-95(B)']:.6f}\")\n",
    "\n",
    "    print(\"\\n========== Final Validation Metrics ==========\")\n",
    "    print(f\"Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "\n",
    "def print_csv_metrics(directory):\n",
    "    \"\"\"Main function to process and print final metrics.\"\"\"\n",
    "    # Find the results.csv file\n",
    "    results_csv_path = find_results_csv(directory)\n",
    "    \n",
    "    if not results_csv_path:\n",
    "        print(\"Error: 'results.csv' file not found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found results.csv at: {results_csv_path}\")\n",
    "\n",
    "    # Load results CSV\n",
    "    df = load_results_csv(results_csv_path)\n",
    "\n",
    "    # Get the total number of epochs\n",
    "    total_epochs = calculate_total_epochs(df)\n",
    "    print(f\"Total number of epochs: {total_epochs}\")\n",
    "\n",
    "    print_final_metrics(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88ee73",
   "metadata": {},
   "source": [
    "### Function to Compare Metrics Between Two YOLO Training Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "801b09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_final_metrics(csv1_path, csv2_path):\n",
    "    df1 = pd.read_csv(csv1_path)\n",
    "    df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "    last1 = df1.iloc[-1]\n",
    "    last2 = df2.iloc[-1]\n",
    "\n",
    "    metrics_to_compare = {\n",
    "        \"train/box_loss\": \"Box Loss (Train)\",\n",
    "        \"train/cls_loss\": \"Cls Loss (Train)\",\n",
    "        \"train/dfl_loss\": \"DFL Loss (Train)\",\n",
    "        \"metrics/precision(B)\": \"Precision\",\n",
    "        \"metrics/recall(B)\": \"Recall\",\n",
    "        \"metrics/mAP50(B)\": \"mAP@0.5\",\n",
    "        \"metrics/mAP50-95(B)\": \"mAP@0.5:0.95\",\n",
    "        \"val/box_loss\": \"Box Loss (Val)\",\n",
    "        \"val/cls_loss\": \"Cls Loss (Val)\",\n",
    "        \"val/dfl_loss\": \"DFL Loss (Val)\"\n",
    "    }\n",
    "\n",
    "    print(\"Changes in Metrics Before and After Retraning:\\n\")\n",
    "    print(f\"{'Metric':<25} {'Before':<10} {'After':<10} {'Diff':<10} {'Trend'}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    for key, label in metrics_to_compare.items():\n",
    "        val1 = last1[key]\n",
    "        val2 = last2[key]\n",
    "        diff = val2 - val1\n",
    "        if abs(diff) > 1e-6:\n",
    "            # If increase, color green; if decrease, color red\n",
    "            if diff > 0:\n",
    "                trend = f\"\\033[92m Increase\\033[0m\"  # Green\n",
    "            else:\n",
    "                trend = f\"\\033[91m Decrease\\033[0m\"  # Red\n",
    "\n",
    "            # Printing with colors\n",
    "            print(f\"{label:<25} {val1:<10.5f} {val2:<10.5f} {diff:<10.5f} {trend}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f884a",
   "metadata": {},
   "source": [
    "### Function to Compare mAP@0.5:0.95 Metrics Between Two Models (Before and After Retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9f96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def compare_maps(json_path1, json_path2):\n",
    "    with open(json_path1, 'r') as f1, open(json_path2, 'r') as f2:\n",
    "        metrics1 = json.load(f1)\n",
    "        metrics2 = json.load(f2)\n",
    "\n",
    "    print(\"\\nmAP@0.5:0.95 Differences Before and After Retraning:\\n\")\n",
    "    print(f\"{'Class':<15} {'Before':<10} {'After':<10} {'Diff':<10} {'Trend'}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for class_name in metrics1:\n",
    "        map1 = metrics1[class_name].get(\"mAP@0.5:0.95\", 0)\n",
    "        map2 = metrics2.get(class_name, {}).get(\"mAP@0.5:0.95\", 0)\n",
    "\n",
    "        diff = map2 - map1\n",
    "        if abs(diff) > 1e-6:\n",
    "            if diff > 0:\n",
    "                trend = f\"\\033[92m Increase\\033[0m\"  # Green for increase\n",
    "            else:\n",
    "                trend = f\"\\033[91m Decrease\\033[0m\"  # Red for decrease\n",
    "\n",
    "            # Printing with colors\n",
    "            print(f\"{class_name:<15} {map1:<10.4f} {map2:<10.4f} {diff:<10.4f} {trend}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571c798",
   "metadata": {},
   "source": [
    "### YOLO Model Evaluation and Metrics Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "565fb52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def load_yolo_model(model_path):\n",
    "    return YOLO(model_path)\n",
    "\n",
    "def run_model_validation(model, yaml):\n",
    "    return model.val(data=yaml)\n",
    "\n",
    "def extract_per_class_metrics(results):\n",
    "    \"\"\"\n",
    "    Extracts mAP@0.5:0.95 per class from results.\n",
    "    NOTE: Only mAP@0.5:0.95 is available via `results.box.maps`\n",
    "    \"\"\"\n",
    "    per_class_metrics = {}\n",
    "    if hasattr(results.box, 'maps') and results.box.maps is not None:\n",
    "        maps = results.box.maps  # This is a NumPy array [num_classes]\n",
    "        for i, name in results.names.items():\n",
    "            per_class_metrics[name] = {\n",
    "                \"class_id\": i,\n",
    "                \"mAP@0.5:0.95\": round(float(maps[i]), 4)\n",
    "            }\n",
    "    else:\n",
    "        print(\"[-] No per-class mAP@0.5:0.95 data found.\")\n",
    "    return per_class_metrics\n",
    "\n",
    "def save_metrics_to_json(metrics, output_path):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    print(f\"[+] Saved per-class metrics to {output_path}\")\n",
    "\n",
    "def evaluate_and_save_metrics(model_path, yaml, output_json_path=\"per_class_metrics.json\"):\n",
    "    model = load_yolo_model(model_path)\n",
    "    results = run_model_validation(model, yaml)\n",
    "    metrics = extract_per_class_metrics(results)\n",
    "    save_metrics_to_json(metrics, output_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89860d7a",
   "metadata": {},
   "source": [
    "### Per-Class mAP@0.5:0.95 Metrics Extraction and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f44129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def print_per_class_metrics(json_path=\"per_class_metrics.json\"):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"Per-Class mAP@0.5:0.95 Metrics:\\n\")\n",
    "    print(f\"{'Class Name':<15} {'Class ID':<10} {'mAP@0.5:0.95':<15}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for name, data in metrics.items():\n",
    "        print(f\"{name:<15} {data['class_id']:<10} {data['mAP@0.5:0.95']:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dbf2a",
   "metadata": {},
   "source": [
    "## Calling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a274fb",
   "metadata": {},
   "source": [
    "### Before Retraning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d24f63fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found results.csv at: ./runs/train/yolov8/results.csv\n",
      "Total number of epochs: 50\n",
      "\n",
      "========== Final Training Metrics ==========\n",
      "Training Loss: 2.047820\n",
      "Precision: 0.643800\n",
      "Recall: 0.268230\n",
      "mAP@0.5: 0.282050\n",
      "mAP@0.5:0.95: 0.177310\n",
      "\n",
      "========== Final Validation Metrics ==========\n",
      "Validation Loss: 5.496680\n"
     ]
    }
   ],
   "source": [
    "yolov8 = './runs/train/yolov8'\n",
    "print_csv_metrics(yolov8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "74072972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Found best.pt at: runs/train/yolov8/weights/best.pt\n",
      "Ultralytics 8.3.109 🚀 Python-3.10.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 OEM, 7957MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ssl49/Desktop/Automated-Labeling-for-Aerial-Images-main/Automated_SegmentAndYolo/datasets/new_dataset_yolo_split/val/labels.cache... 1181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1181/1181 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:10<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1181      70393      0.577       0.27       0.29      0.186\n",
      "                  pool          9          9      0.757      0.889      0.889      0.731\n",
      "            vegetation         75       1780      0.155      0.254      0.149     0.0798\n",
      "                  roof         42         79     0.0743      0.696      0.527      0.377\n",
      "                  wall         62        255      0.067      0.208     0.0843     0.0513\n",
      "                window         38        139      0.527      0.201      0.243      0.152\n",
      "                person         75        637       0.82      0.262      0.369      0.188\n",
      "                   dog          6         12          1          0    0.00567    0.00295\n",
      "                   car       1115      53669      0.796      0.289      0.491      0.246\n",
      "               bicycle         32         53      0.477       0.31      0.326      0.103\n",
      "                  tree         38        108      0.869      0.389      0.512      0.356\n",
      "                 truck        907       3904          0          0     0.0535     0.0291\n",
      "                   bus        169        169          1          0          0          0\n",
      "               vehicle       1079       9579      0.957     0.0103      0.125     0.0955\n",
      "Speed: 0.2ms preprocess, 2.9ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "[+] Saved per-class metrics to per_class_metrics.json\n"
     ]
    }
   ],
   "source": [
    "best_pt_path = find_best_model(yolov8)\n",
    "evaluate_and_save_metrics(best_pt_path, yaml=\"yolov8.yaml\",output_json_path=\"per_class_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9f87c283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class mAP@0.5:0.95 Metrics:\n",
      "\n",
      "Class Name      Class ID   mAP@0.5:0.95   \n",
      "----------------------------------------\n",
      "unlabeled       0          0.1855         \n",
      "pool            1          0.7305         \n",
      "vegetation      2          0.0798         \n",
      "roof            3          0.3768         \n",
      "wall            4          0.0513         \n",
      "window          5          0.1524         \n",
      "person          6          0.1884         \n",
      "dog             7          0.0029         \n",
      "car             8          0.2459         \n",
      "bicycle         9          0.1027         \n",
      "tree            10         0.3563         \n",
      "truck           11         0.0291         \n",
      "bus             12         0.0            \n",
      "vehicle         13         0.0955         \n"
     ]
    }
   ],
   "source": [
    "print_per_class_metrics(\"per_class_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe6772",
   "metadata": {},
   "source": [
    "### After Retraning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e8d41ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found results.csv at: ./runs/train/fine-tune-yolov8/results.csv\n",
      "Total number of epochs: 11\n",
      "\n",
      "========== Final Training Metrics ==========\n",
      "Training Loss: 2.637500\n",
      "Precision: 0.627330\n",
      "Recall: 0.537950\n",
      "mAP@0.5: 0.553620\n",
      "mAP@0.5:0.95: 0.399380\n",
      "\n",
      "========== Final Validation Metrics ==========\n",
      "Validation Loss: 2.982540\n"
     ]
    }
   ],
   "source": [
    "new_path = './runs/train/fine-tune-yolov8'\n",
    "print_csv_metrics(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c511331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Found best.pt at: runs/train/fine-tune-yolov8/weights/best.pt\n",
      "Ultralytics 8.3.109 🚀 Python-3.10.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 OEM, 7957MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ssl49/Desktop/Automated-Labeling-for-Aerial-Images-main/Automated_SegmentAndYolo/datasets/split_videos_dataset/val/labels.cache... 109 images, 0 backgrounds, 0 corrupt: 100%|██████████| 109/109 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        109        421      0.101      0.378      0.108     0.0715\n",
      "            vegetation         44         55     0.0415      0.473      0.041     0.0208\n",
      "                  roof         12         13     0.0171      0.154     0.0121    0.00811\n",
      "                person         15         15     0.0723        0.2     0.0466     0.0166\n",
      "                   car         74        281      0.192      0.648      0.179      0.111\n",
      "                  tree         24         33          0          0     0.0805     0.0636\n",
      "               vehicle         16         24      0.281      0.792       0.29      0.209\n",
      "Speed: 0.9ms preprocess, 3.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "[+] Saved per-class metrics to per_class_metrics_retrain.json\n"
     ]
    }
   ],
   "source": [
    "best_pt_path = find_best_model(new_path)\n",
    "evaluate_and_save_metrics(best_pt_path, yaml=\"yolo_retrain.yaml\",output_json_path=\"per_class_metrics_retrain.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d016be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class mAP@0.5:0.95 Metrics:\n",
      "\n",
      "Class Name      Class ID   mAP@0.5:0.95   \n",
      "----------------------------------------\n",
      "unlabeled       0          0.0715         \n",
      "pool            1          0.0715         \n",
      "vegetation      2          0.0208         \n",
      "roof            3          0.0081         \n",
      "wall            4          0.0715         \n",
      "window          5          0.0715         \n",
      "person          6          0.0166         \n",
      "dog             7          0.0715         \n",
      "car             8          0.1107         \n",
      "bicycle         9          0.0715         \n",
      "tree            10         0.0636         \n",
      "truck           11         0.0715         \n",
      "bus             12         0.0715         \n",
      "vehicle         13         0.2094         \n"
     ]
    }
   ],
   "source": [
    "print_per_class_metrics(\"per_class_metrics_retrain.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22530f34",
   "metadata": {},
   "source": [
    "### Compare both metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0187f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes in Metrics Before and After Retraning:\n",
      "\n",
      "Metric                    Before     After      Diff       Trend\n",
      "-----------------------------------------------------------------\n",
      "Box Loss (Train)          0.73327    0.98916    0.25589    \u001b[92m Increase\u001b[0m\n",
      "Cls Loss (Train)          0.45441    0.70747    0.25306    \u001b[92m Increase\u001b[0m\n",
      "DFL Loss (Train)          0.86014    0.94087    0.08073    \u001b[92m Increase\u001b[0m\n",
      "Precision                 0.64380    0.62733    -0.01647   \u001b[91m Decrease\u001b[0m\n",
      "Recall                    0.26823    0.53795    0.26972    \u001b[92m Increase\u001b[0m\n",
      "mAP@0.5                   0.28205    0.55362    0.27157    \u001b[92m Increase\u001b[0m\n",
      "mAP@0.5:0.95              0.17731    0.39938    0.22207    \u001b[92m Increase\u001b[0m\n",
      "Box Loss (Val)            2.02042    0.99684    -1.02358   \u001b[91m Decrease\u001b[0m\n",
      "Cls Loss (Val)            2.42410    0.97288    -1.45122   \u001b[91m Decrease\u001b[0m\n",
      "DFL Loss (Val)            1.05216    1.01282    -0.03934   \u001b[91m Decrease\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "new_path = './runs/train/fine-tune-yolov8'\n",
    "old_path = './runs/train/yolov8'\n",
    "\n",
    "results_csv_path = find_results_csv(new_path)\n",
    "results_csv_path_1 = find_results_csv(old_path)\n",
    "\n",
    "compare_final_metrics(results_csv_path_1, results_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5c726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mAP@0.5:0.95 Differences Before and After Retraning:\n",
      "\n",
      "Class           Before     After      Diff       Trend\n",
      "------------------------------------------------------------\n",
      "unlabeled       0.1855     0.0715     -0.1140    \u001b[91m Decrease\u001b[0m\n",
      "pool            0.7305     0.0715     -0.6590    \u001b[91m Decrease\u001b[0m\n",
      "vegetation      0.0798     0.0208     -0.0590    \u001b[91m Decrease\u001b[0m\n",
      "roof            0.3768     0.0081     -0.3687    \u001b[91m Decrease\u001b[0m\n",
      "wall            0.0513     0.0715     0.0202     \u001b[92m Increase\u001b[0m\n",
      "window          0.1524     0.0715     -0.0809    \u001b[91m Decrease\u001b[0m\n",
      "person          0.1884     0.2166     0.0282     \u001b[92m Increase\u001b[0m\n",
      "dog             0.0029     0.0715     0.0686     \u001b[92m Increase\u001b[0m\n",
      "car             0.2459     0.3107     0.0648     \u001b[92m Increase\u001b[0m\n",
      "bicycle         0.1027     0.0715     -0.0312    \u001b[91m Decrease\u001b[0m\n",
      "tree            0.3563     0.0636     -0.2927    \u001b[91m Decrease\u001b[0m\n",
      "truck           0.0291     0.0715     0.0424     \u001b[92m Increase\u001b[0m\n",
      "bus             0.0000     0.0715     0.0715     \u001b[92m Increase\u001b[0m\n",
      "vehicle         0.0955     0.2094     0.1139     \u001b[92m Increase\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "compare_maps(\"per_class_metrics.json\", \"per_class_metrics_retrain.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
