{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f439d446",
   "metadata": {},
   "source": [
    "# Print Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f39c31",
   "metadata": {},
   "source": [
    "## Creating Required Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4380a4",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cc21d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07427de3",
   "metadata": {},
   "source": [
    "### Function to Find the Best YOLO Model (best.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7608373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_dir='runs_yolo/'):\n",
    "    best_paths = list(Path(base_dir).rglob('best.pt'))\n",
    "    if not best_paths:\n",
    "        raise FileNotFoundError(\"No 'best.pt' file found in the 'runs/' directory.\")\n",
    "    \n",
    "    # Optionally, sort by latest modified time\n",
    "    best_paths.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    print(f\"[+] Found best.pt at: {best_paths[0]}\")\n",
    "    return str(best_paths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d57524",
   "metadata": {},
   "source": [
    "### Functions to Load and Print Metrics from YOLO Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f287ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_results_csv(directory):\n",
    "    \"\"\"Find the results.csv file in the specified directory.\"\"\"\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if 'results.csv' in files:\n",
    "            return os.path.join(root, 'results.csv')\n",
    "    return None\n",
    "\n",
    "def load_results_csv(results_csv_path):\n",
    "    \"\"\"Load the results CSV into a pandas DataFrame.\"\"\"\n",
    "    return pd.read_csv(results_csv_path)\n",
    "\n",
    "def calculate_total_epochs(df):\n",
    "    \"\"\"Calculate the total number of epochs from the DataFrame.\"\"\"\n",
    "    return df['epoch'].max()\n",
    "\n",
    "def calculate_training_loss(epoch_data):\n",
    "    \"\"\"Calculate the total training loss from the given epoch data.\"\"\"\n",
    "    train_box_loss = epoch_data['train/box_loss']\n",
    "    train_cls_loss = epoch_data['train/cls_loss']\n",
    "    train_dfl_loss = epoch_data['train/dfl_loss']\n",
    "    return train_box_loss + train_cls_loss + train_dfl_loss\n",
    "\n",
    "def calculate_validation_loss(epoch_data):\n",
    "    \"\"\"Calculate the total validation loss from the given epoch data.\"\"\"\n",
    "    val_box_loss = epoch_data['val/box_loss']\n",
    "    val_cls_loss = epoch_data['val/cls_loss']\n",
    "    val_dfl_loss = epoch_data['val/dfl_loss']\n",
    "    return val_box_loss + val_cls_loss + val_dfl_loss\n",
    "\n",
    "def print_final_metrics(df):\n",
    "    \"\"\"Print the final metrics for the last epoch.\"\"\"\n",
    "    final_epoch_data = df.iloc[-1]\n",
    "\n",
    "    # Calculate total training and validation loss\n",
    "    train_loss = calculate_training_loss(final_epoch_data)\n",
    "    val_loss = calculate_validation_loss(final_epoch_data)\n",
    "\n",
    "    # Print overall metrics\n",
    "    print(\"\\n========== Final Training Metrics ==========\")\n",
    "    print(f\"Training Loss: {train_loss:.6f}\")\n",
    "    print(f\"Precision: {final_epoch_data['metrics/precision(B)']:.6f}\")\n",
    "    print(f\"Recall: {final_epoch_data['metrics/recall(B)']:.6f}\")\n",
    "    print(f\"mAP@0.5: {final_epoch_data['metrics/mAP50(B)']:.6f}\")\n",
    "    print(f\"mAP@0.5:0.95: {final_epoch_data['metrics/mAP50-95(B)']:.6f}\")\n",
    "\n",
    "    print(\"\\n========== Final Validation Metrics ==========\")\n",
    "    print(f\"Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "\n",
    "def print_csv_metrics(directory):\n",
    "    \"\"\"Main function to process and print final metrics.\"\"\"\n",
    "    # Find the results.csv file\n",
    "    results_csv_path = find_results_csv(directory)\n",
    "    \n",
    "    if not results_csv_path:\n",
    "        print(\"Error: 'results.csv' file not found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found results.csv at: {results_csv_path}\")\n",
    "\n",
    "    # Load results CSV\n",
    "    df = load_results_csv(results_csv_path)\n",
    "\n",
    "    # Get the total number of epochs\n",
    "    total_epochs = calculate_total_epochs(df)\n",
    "    print(f\"Total number of epochs: {total_epochs}\")\n",
    "\n",
    "    print_final_metrics(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88ee73",
   "metadata": {},
   "source": [
    "### Function to Compare Metrics Between Two YOLO Training Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "801b09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_final_metrics(csv1_path, csv2_path):\n",
    "    df1 = pd.read_csv(csv1_path)\n",
    "    df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "    last1 = df1.iloc[-1]\n",
    "    last2 = df2.iloc[-1]\n",
    "\n",
    "    metrics_to_compare = {\n",
    "        \"train/box_loss\": \"Box Loss (Train)\",\n",
    "        \"train/cls_loss\": \"Cls Loss (Train)\",\n",
    "        \"train/dfl_loss\": \"DFL Loss (Train)\",\n",
    "        \"metrics/precision(B)\": \"Precision\",\n",
    "        \"metrics/recall(B)\": \"Recall\",\n",
    "        \"metrics/mAP50(B)\": \"mAP@0.5\",\n",
    "        \"metrics/mAP50-95(B)\": \"mAP@0.5:0.95\",\n",
    "        \"val/box_loss\": \"Box Loss (Val)\",\n",
    "        \"val/cls_loss\": \"Cls Loss (Val)\",\n",
    "        \"val/dfl_loss\": \"DFL Loss (Val)\"\n",
    "    }\n",
    "\n",
    "    print(\"Changes in Metrics Before and After Retraning:\\n\")\n",
    "    print(f\"{'Metric':<25} {'Before':<10} {'After':<10} {'Diff':<10} {'Trend'}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    for key, label in metrics_to_compare.items():\n",
    "        val1 = last1[key]\n",
    "        val2 = last2[key]\n",
    "        diff = val2 - val1\n",
    "        if abs(diff) > 1e-6:\n",
    "            # If increase, color green; if decrease, color red\n",
    "            if diff > 0:\n",
    "                trend = f\"\\033[92m Increase\\033[0m\"  # Green\n",
    "            else:\n",
    "                trend = f\"\\033[91m Decrease\\033[0m\"  # Red\n",
    "\n",
    "            # Printing with colors\n",
    "            print(f\"{label:<25} {val1:<10.5f} {val2:<10.5f} {diff:<10.5f} {trend}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f884a",
   "metadata": {},
   "source": [
    "### Function to Compare mAP@0.5:0.95 Metrics Between Two Models (Before and After Retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f9f96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def compare_maps(json_path1, json_path2):\n",
    "    with open(json_path1, 'r') as f1, open(json_path2, 'r') as f2:\n",
    "        metrics1 = json.load(f1)\n",
    "        metrics2 = json.load(f2)\n",
    "\n",
    "    print(\"\\nmAP@0.5:0.95 Differences Before and After Retraning:\\n\")\n",
    "    print(f\"{'Class':<15} {'Before':<10} {'After':<10} {'Diff':<10} {'Trend'}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for class_name in metrics1:\n",
    "        map1 = metrics1[class_name].get(\"mAP@0.5:0.95\", 0)\n",
    "        map2 = metrics2.get(class_name, {}).get(\"mAP@0.5:0.95\", 0)\n",
    "\n",
    "        diff = map2 - map1\n",
    "        if abs(diff) > 1e-6:\n",
    "            if diff > 0:\n",
    "                trend = f\"\\033[92m Increase\\033[0m\"  # Green for increase\n",
    "            else:\n",
    "                trend = f\"\\033[91m Decrease\\033[0m\"  # Red for decrease\n",
    "\n",
    "            # Printing with colors\n",
    "            print(f\"{class_name:<15} {map1:<10.4f} {map2:<10.4f} {diff:<10.4f} {trend}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571c798",
   "metadata": {},
   "source": [
    "### YOLO Model Evaluation and Metrics Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "565fb52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def load_yolo_model(model_path):\n",
    "    return YOLO(model_path)\n",
    "\n",
    "def run_model_validation(model, yaml):\n",
    "    return model.val(data=yaml)\n",
    "\n",
    "def extract_per_class_metrics(results):\n",
    "    \"\"\"\n",
    "    Extracts mAP@0.5:0.95 per class from results.\n",
    "    NOTE: Only mAP@0.5:0.95 is available via `results.box.maps`\n",
    "    \"\"\"\n",
    "    per_class_metrics = {}\n",
    "    if hasattr(results.box, 'maps') and results.box.maps is not None:\n",
    "        maps = results.box.maps  # This is a NumPy array [num_classes]\n",
    "        for i, name in results.names.items():\n",
    "            per_class_metrics[name] = {\n",
    "                \"class_id\": i,\n",
    "                \"mAP@0.5:0.95\": round(float(maps[i]), 4)\n",
    "            }\n",
    "    else:\n",
    "        print(\"[-] No per-class mAP@0.5:0.95 data found.\")\n",
    "    return per_class_metrics\n",
    "\n",
    "def save_metrics_to_json(metrics, output_path):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    print(f\"[+] Saved per-class metrics to {output_path}\")\n",
    "\n",
    "def evaluate_and_save_metrics(model_path, yaml, output_json_path=\"per_class_metrics.json\"):\n",
    "    model = load_yolo_model(model_path)\n",
    "    results = run_model_validation(model, yaml)\n",
    "    metrics = extract_per_class_metrics(results)\n",
    "    save_metrics_to_json(metrics, output_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89860d7a",
   "metadata": {},
   "source": [
    "### Per-Class mAP@0.5:0.95 Metrics Extraction and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f44129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def print_per_class_metrics(json_path=\"per_class_metrics.json\"):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"Per-Class mAP@0.5:0.95 Metrics:\\n\")\n",
    "    print(f\"{'Class Name':<15} {'Class ID':<10} {'mAP@0.5:0.95':<15}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for name, data in metrics.items():\n",
    "        print(f\"{name:<15} {data['class_id']:<10} {data['mAP@0.5:0.95']:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dbf2a",
   "metadata": {},
   "source": [
    "## Calling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a274fb",
   "metadata": {},
   "source": [
    "### Before Retraning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d24f63fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found results.csv at: ./runs/train/yolov8\\results.csv\n",
      "Total number of epochs: 50\n",
      "\n",
      "========== Final Training Metrics ==========\n",
      "Training Loss: 2.047820\n",
      "Precision: 0.643800\n",
      "Recall: 0.268230\n",
      "mAP@0.5: 0.282050\n",
      "mAP@0.5:0.95: 0.177310\n",
      "\n",
      "========== Final Validation Metrics ==========\n",
      "Validation Loss: 5.496680\n"
     ]
    }
   ],
   "source": [
    "yolov8 = './runs/train/yolov8'\n",
    "print_csv_metrics(yolov8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74072972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Found best.pt at: runs\\train\\yolov8\\weights\\best.pt\n",
      "Ultralytics 8.3.107  Python-3.12.4 torch-2.5.1+cpu CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
      "Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sande\\OneDrive\\Desktop\\IITTP\\2_Asgn\\Sem2\\2_dl\\SemProject\\Automated_SegmentAndYolo\\datasets\\new_dataset_yolo_split\\val\\labels.cache... 1181 images, 1 backgrounds, 0 corrupt: 100%|██████████| 1181/1181 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [02:22<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1181      69465      0.656      0.275       0.34      0.232\n",
      "                  pool          9          9      0.908          1      0.995      0.851\n",
      "            vegetation         73       1130      0.318      0.239      0.179      0.107\n",
      "                  roof         38         59     0.0735      0.576      0.487      0.406\n",
      "                  wall         52        220      0.166      0.227      0.167      0.116\n",
      "                window         27         67      0.701      0.179      0.207      0.118\n",
      "                person         71        523       0.91      0.272      0.419      0.247\n",
      "                   dog          8         14          1          0      0.186      0.144\n",
      "                   car       1110      53660       0.84      0.238       0.49      0.245\n",
      "               bicycle         32         70      0.708      0.485      0.615       0.29\n",
      "                  tree         31         61      0.915      0.352      0.501      0.368\n",
      "                 truck        907       3904          0          0     0.0539     0.0295\n",
      "                   bus        169        169          1          0          0          0\n",
      "               vehicle       1079       9579      0.988    0.00846      0.125     0.0959\n",
      "Speed: 0.9ms preprocess, 42.8ms inference, 0.0ms loss, 61.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val12\u001b[0m\n",
      "[+] Saved per-class metrics to per_class_metrics.json\n"
     ]
    }
   ],
   "source": [
    "best_pt_path = find_best_model(yolov8)\n",
    "evaluate_and_save_metrics(best_pt_path, yaml=\"yolov8.yaml\",output_json_path=\"per_class_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f87c283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class mAP@0.5:0.95 Metrics:\n",
      "\n",
      "Class Name      Class ID   mAP@0.5:0.95   \n",
      "----------------------------------------\n",
      "unlabeled       0          0.2322         \n",
      "pool            1          0.8511         \n",
      "vegetation      2          0.107          \n",
      "roof            3          0.4061         \n",
      "wall            4          0.1156         \n",
      "window          5          0.1175         \n",
      "person          6          0.2474         \n",
      "dog             7          0.1438         \n",
      "car             8          0.2454         \n",
      "bicycle         9          0.2903         \n",
      "tree            10         0.3684         \n",
      "truck           11         0.0295         \n",
      "bus             12         0.0            \n",
      "vehicle         13         0.0959         \n"
     ]
    }
   ],
   "source": [
    "print_per_class_metrics(\"per_class_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe6772",
   "metadata": {},
   "source": [
    "### After Retraning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8d41ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found results.csv at: ./runs/train/fine-tune-yolov8\\results.csv\n",
      "Total number of epochs: 11\n",
      "\n",
      "========== Final Training Metrics ==========\n",
      "Training Loss: 2.637500\n",
      "Precision: 0.627330\n",
      "Recall: 0.537950\n",
      "mAP@0.5: 0.553620\n",
      "mAP@0.5:0.95: 0.399380\n",
      "\n",
      "========== Final Validation Metrics ==========\n",
      "Validation Loss: 2.982540\n"
     ]
    }
   ],
   "source": [
    "new_path = './runs/train/fine-tune-yolov8'\n",
    "print_csv_metrics(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c511331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Found best.pt at: runs\\train\\fine-tune-yolov8\\weights\\best.pt\n",
      "Ultralytics 8.3.107  Python-3.12.4 torch-2.5.1+cpu CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sande\\OneDrive\\Desktop\\IITTP\\2_Asgn\\Sem2\\2_dl\\SemProject\\Automated_SegmentAndYolo\\datasets\\split_videos_dataset\\val\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          6      0.432      0.583      0.636       0.46\n",
      "                  wall          1          1          1          0          0          0\n",
      "                person          1          1      0.137          1      0.995      0.438\n",
      "                  tree          1          3      0.388      0.333      0.555      0.506\n",
      "               vehicle          1          1      0.202          1      0.995      0.895\n",
      "Speed: 1.0ms preprocess, 52.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val13\u001b[0m\n",
      "[+] Saved per-class metrics to per_class_metrics_retrain.json\n"
     ]
    }
   ],
   "source": [
    "best_pt_path = find_best_model(new_path)\n",
    "evaluate_and_save_metrics(best_pt_path, yaml=\"yolo_retrain.yaml\",output_json_path=\"per_class_metrics_retrain.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d016be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class mAP@0.5:0.95 Metrics:\n",
      "\n",
      "Class Name      Class ID   mAP@0.5:0.95   \n",
      "----------------------------------------\n",
      "unlabeled       0          0.4599         \n",
      "pool            1          0.4599         \n",
      "vegetation      2          0.4599         \n",
      "roof            3          0.4599         \n",
      "wall            4          0.0            \n",
      "window          5          0.4599         \n",
      "person          6          0.4378         \n",
      "dog             7          0.4599         \n",
      "car             8          0.4599         \n",
      "bicycle         9          0.4599         \n",
      "tree            10         0.5064         \n",
      "truck           11         0.4599         \n",
      "bus             12         0.4599         \n",
      "vehicle         13         0.8955         \n"
     ]
    }
   ],
   "source": [
    "print_per_class_metrics(\"per_class_metrics_retrain.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22530f34",
   "metadata": {},
   "source": [
    "### Compare both metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0187f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes in Metrics Before and After Retraning:\n",
      "\n",
      "Metric                    Before     After      Diff       Trend\n",
      "-----------------------------------------------------------------\n",
      "Box Loss (Train)          0.73327    0.98916    0.25589    \u001b[92m Increase\u001b[0m\n",
      "Cls Loss (Train)          0.45441    0.70747    0.25306    \u001b[92m Increase\u001b[0m\n",
      "DFL Loss (Train)          0.86014    0.94087    0.08073    \u001b[92m Increase\u001b[0m\n",
      "Precision                 0.64380    0.62733    -0.01647   \u001b[91m Decrease\u001b[0m\n",
      "Recall                    0.26823    0.53795    0.26972    \u001b[92m Increase\u001b[0m\n",
      "mAP@0.5                   0.28205    0.55362    0.27157    \u001b[92m Increase\u001b[0m\n",
      "mAP@0.5:0.95              0.17731    0.39938    0.22207    \u001b[92m Increase\u001b[0m\n",
      "Box Loss (Val)            2.02042    0.99684    -1.02358   \u001b[91m Decrease\u001b[0m\n",
      "Cls Loss (Val)            2.42410    0.97288    -1.45122   \u001b[91m Decrease\u001b[0m\n",
      "DFL Loss (Val)            1.05216    1.01282    -0.03934   \u001b[91m Decrease\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "new_path = './runs/train/fine-tune-yolov8'\n",
    "old_path = './runs/train/yolov8'\n",
    "\n",
    "results_csv_path = find_results_csv(new_path)\n",
    "results_csv_path_1 = find_results_csv(old_path)\n",
    "\n",
    "compare_final_metrics(results_csv_path_1, results_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb5c726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mAP@0.5:0.95 Differences Before and After Retraning:\n",
      "\n",
      "Class           Before     After      Diff       Trend\n",
      "------------------------------------------------------------\n",
      "unlabeled       0.2322     0.4599     0.2277     \u001b[92m Increase\u001b[0m\n",
      "pool            0.8511     0.4599     -0.3912    \u001b[91m Decrease\u001b[0m\n",
      "vegetation      0.1070     0.4599     0.3529     \u001b[92m Increase\u001b[0m\n",
      "roof            0.4061     0.4599     0.0538     \u001b[92m Increase\u001b[0m\n",
      "wall            0.1156     0.0000     -0.1156    \u001b[91m Decrease\u001b[0m\n",
      "window          0.1175     0.4599     0.3424     \u001b[92m Increase\u001b[0m\n",
      "person          0.2474     0.4378     0.1904     \u001b[92m Increase\u001b[0m\n",
      "dog             0.1438     0.4599     0.3161     \u001b[92m Increase\u001b[0m\n",
      "car             0.2454     0.4599     0.2145     \u001b[92m Increase\u001b[0m\n",
      "bicycle         0.2903     0.4599     0.1696     \u001b[92m Increase\u001b[0m\n",
      "tree            0.3684     0.5064     0.1380     \u001b[92m Increase\u001b[0m\n",
      "truck           0.0295     0.4599     0.4304     \u001b[92m Increase\u001b[0m\n",
      "bus             0.0000     0.4599     0.4599     \u001b[92m Increase\u001b[0m\n",
      "vehicle         0.0959     0.8955     0.7996     \u001b[92m Increase\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "compare_maps(\"per_class_metrics.json\", \"per_class_metrics_retrain.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
