{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6960fbb5",
   "metadata": {},
   "source": [
    "### Live Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baec892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8cd62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_to_name = {\n",
    "    0:  ('road', [28, 42, 168]),\n",
    "    1:  ('pool', [0, 50, 89]),\n",
    "    2:  ('vegetation', [107, 142, 35]),\n",
    "    3:  ('roof', [70, 70, 70]),\n",
    "    4:  ('wall', [102, 102, 156]),\n",
    "    5:  ('window', [254, 228, 12]),\n",
    "    6:  ('person', [255, 22, 96]),\n",
    "    7:  ('dog', [102, 51, 0]),\n",
    "    8:  ('car', [9, 143, 150]),\n",
    "    9:  ('bicycle', [119, 11, 32]),\n",
    "    10: ('tree', [51, 51, 0]),\n",
    "    11: ('truck', [160, 160, 60]),   # added truck\n",
    "    12: ('bus', [200, 80, 80]),      # added bus\n",
    "    13: ('vehicle', [20, 80, 80]),      # added bus\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6fe5cd",
   "metadata": {},
   "source": [
    "# YOLOv8 Live Object Detection with Webcam\n",
    "\n",
    "This script performs live object detection using a YOLOv8 model and displays the annotated frames in real-time. It also supports saving the annotated frames and YOLO format labels if needed.\n",
    "\n",
    "## Features\n",
    "- **Live Object Detection**: Annotates objects in real-time from the webcam feed.\n",
    "- **Custom Class-Color Mapping**: Each class is assigned a unique color for bounding box annotation.\n",
    "- **Save Option**: Optionally save frames and YOLO formatted labels to a specified directory.\n",
    "\n",
    "### Functions:\n",
    "1. **`load_model`**: Loads the YOLO model from the given path.\n",
    "2. **`predict_frame`**: Runs object detection on each frame and annotates it with bounding boxes and class labels.\n",
    "3. **`run_webcam_detection`**: Captures video from the webcam and continuously processes each frame using the model.\n",
    "\n",
    "### Usage:\n",
    "- Press `'q'` to exit the live detection loop.\n",
    "- Annotated frames and labels are saved in YOLO format if the `save` parameter is set to `True`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b7109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "def load_model(model_path=\"best.pt\"):\n",
    "    return YOLO(model_path)\n",
    "\n",
    "def predict_frame(model, frame, conf_thresh=0.5, save_dir=None, frame_id=\"0000\"):\n",
    "    results = model.predict(source=frame, conf=conf_thresh, verbose=False)\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    # Prepare directories\n",
    "    if save_dir:\n",
    "        os.makedirs(f\"{save_dir}/images\", exist_ok=True)\n",
    "        os.makedirs(f\"{save_dir}/labels\", exist_ok=True)\n",
    "\n",
    "    label_lines = []\n",
    "    \n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            class_name, color = class_id_to_name.get(cls_id, (f\"class_{cls_id}\", [0, 255, 0]))\n",
    "            label = f\"{class_name}: {conf:.2f}\"\n",
    "\n",
    "            # Draw on image (annotation)\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(annotated, label, (x1, max(y1 - 10, 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            if save_dir:\n",
    "                # YOLO format: class_id x_center y_center width height (normalized)\n",
    "                h, w, _ = frame.shape\n",
    "                xc = (x1 + x2) / 2 / w\n",
    "                yc = (y1 + y2) / 2 / h\n",
    "                bw = (x2 - x1) / w\n",
    "                bh = (y2 - y1) / h\n",
    "                label_lines.append(f\"{cls_id} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "    if save_dir:\n",
    "        # Save original image (real image)\n",
    "        cv2.imwrite(f\"{save_dir}/images/frame_{frame_id}.jpg\", frame)\n",
    "        # Save label in YOLO format\n",
    "        with open(f\"{save_dir}/labels/frame_{frame_id}.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "    return annotated\n",
    "\n",
    "def compare_two_models_live(model_a_path=\"best.pt\", model_b_path=\"best.pt\", save=False):\n",
    "    # Load two models\n",
    "    model_a = load_model(model_a_path)\n",
    "    model_b = load_model(model_b_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    save_dir = \"output\" if save else None\n",
    "    frame_count = 0\n",
    "\n",
    "    print(\"Press 'q' to exit...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id = f\"{frame_count:05d}\"\n",
    "\n",
    "        # Annotate frames using both models\n",
    "        left_frame = predict_frame(model_a, frame, save_dir=save_dir, frame_id=frame_id)\n",
    "        right_frame = predict_frame(model_b, frame, save_dir=save_dir, frame_id=frame_id)\n",
    "\n",
    "        # Resize frames to a consistent height while maintaining the aspect ratio\n",
    "        target_height = 420  # Target height for resizing\n",
    "        left_resized = resize_to_height(left_frame, target_height)\n",
    "        right_resized = resize_to_height(right_frame, target_height)\n",
    "\n",
    "        # Find the maximum width between the two resized frames to align them horizontally\n",
    "        combined_width = left_resized.shape[1] + right_resized.shape[1]\n",
    "        combined_frame = cv2.hconcat([left_resized, right_resized])\n",
    "\n",
    "        # Display the combined output of both models\n",
    "        cv2.imshow(\"Compare: Train Model (Left) vs Retrain Model (Right)\", combined_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def resize_to_height(image, target_height=420):\n",
    "    \"\"\"\n",
    "    Resize image while maintaining aspect ratio.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    scale = target_height / h\n",
    "    new_w = int(w * scale)\n",
    "    return cv2.resize(image, (new_w, target_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3424b93",
   "metadata": {},
   "source": [
    "# Function to Find the Best YOLO Model\n",
    "\n",
    "This function `find_best_model` is used to locate the most recent `best.pt` file from the specified directory. The model is searched recursively within the given base directory, and the most recent one is selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ada6e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_dir='runs_yolo/'):\n",
    "    best_paths = list(Path(base_dir).rglob('best.pt'))\n",
    "    if not best_paths:\n",
    "        raise FileNotFoundError(\"No 'best.pt' file found in the 'runs/' directory.\")\n",
    "    \n",
    "    # Optionally, sort by latest modified time\n",
    "    best_paths.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    print(f\"âœ… Found best.pt at: {best_paths[0]}\")\n",
    "    return str(best_paths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480157b2",
   "metadata": {},
   "source": [
    "# Visualization of Random Images with Bounding Boxes\n",
    "\n",
    "This code provides a function to visualize random images from a dataset with bounding boxes drawn from YOLO format label files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "378ea3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to draw bounding boxes from YOLO format labels\n",
    "def draw_bounding_boxes(image, label_path, class_id_to_name):\n",
    "    with open(label_path, \"r\") as file:\n",
    "        labels = file.readlines()\n",
    "\n",
    "    for label in labels:\n",
    "        parts = label.strip().split()\n",
    "        class_id = int(parts[0])\n",
    "        xc, yc, bw, bh = map(float, parts[1:])\n",
    "        \n",
    "        # Get the image dimensions\n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        # Convert YOLO format to pixel values\n",
    "        x1 = int((xc - bw / 2) * w)\n",
    "        y1 = int((yc - bh / 2) * h)\n",
    "        x2 = int((xc + bw / 2) * w)\n",
    "        y2 = int((yc + bh / 2) * h)\n",
    "\n",
    "        # Get class name and color\n",
    "        class_name, color = class_id_to_name.get(class_id, (f\"class_{class_id}\", [0, 255, 0]))\n",
    "\n",
    "        # Draw the bounding box and label\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, f\"{class_name}\", (x1, max(y1 - 10, 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "def visualize_random_images(images_dir=\"./datasets/split_videos_dataset/train/images\", \n",
    "                            labels_dir=\"./datasets/split_videos_dataset/train/labels\", \n",
    "                            num_images=10, \n",
    "                            max_display_size=800):\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "    random_images = random.sample(image_files, min(num_images, len(image_files)))\n",
    "\n",
    "    for image_file in random_images:\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        label_path = os.path.join(labels_dir, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: No label file found for {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Failed to read {image_path}\")\n",
    "            continue\n",
    "\n",
    "        print(\"Image:\", image_path)\n",
    "        image_with_boxes = draw_bounding_boxes(image, label_path, class_id_to_name)\n",
    "\n",
    "        # Resize image to fit screen\n",
    "        h, w = image_with_boxes.shape[:2]\n",
    "        scale = min(max_display_size / max(h, w), 1.0)\n",
    "        resized = cv2.resize(image_with_boxes, (int(w * scale), int(h * scale)))\n",
    "\n",
    "        # Display image\n",
    "        cv2.imshow(f\"Image: {image_file}\", resized)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a3c8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# def check_cameras():\n",
    "#     # Try accessing different camera indices, typically 0 is the default (laptop camera)\n",
    "#     for i in range(5):  # You can increase the range if you have more cameras\n",
    "#         cap = cv2.VideoCapture(i)\n",
    "#         if cap.isOpened():\n",
    "#             print(f\"Camera {i} is accessible.\")\n",
    "#             ret, frame = cap.read()\n",
    "#             if ret:\n",
    "#                 print(f\"Camera {i} is showing a frame.\")\n",
    "#                 cv2.imshow(f\"Camera {i}\", frame)\n",
    "#                 cv2.waitKey(0)  # Wait for any key to close the window\n",
    "#             cap.release()\n",
    "#         else:\n",
    "#             print(f\"Camera {i} is not accessible.\")\n",
    "\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Call the function to check for cameras\n",
    "# check_cameras()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f452e161",
   "metadata": {},
   "source": [
    "### Using Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b676d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found best.pt at: runs\\train\\yolov8\\weights\\best.pt\n",
      "âœ… Found best.pt at: runs\\train\\fine-tune-yolov8\\weights\\best.pt\n",
      "Press 'q' to exit...\n"
     ]
    }
   ],
   "source": [
    "yolov8 = './runs/train/yolov8'\n",
    "yolov8_retrain = './runs/train/fine-tune-yolov8'\n",
    "\n",
    "best_pt_path = find_best_model(yolov8)\n",
    "best_pt_path_retrain = find_best_model(yolov8_retrain)\n",
    "\n",
    "# Run webcam detection with two models\n",
    "compare_two_models_live(model_a_path=best_pt_path, model_b_path=best_pt_path_retrain, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8df9d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: ./output/images\\frame_00570.jpg\n",
      "Image: ./output/images\\frame_00435.jpg\n",
      "Image: ./output/images\\frame_00333.jpg\n",
      "Image: ./output/images\\frame_00322.jpg\n",
      "Image: ./output/images\\frame_00211.jpg\n"
     ]
    }
   ],
   "source": [
    "# Function to visualize random images and bounding boxes\n",
    "visualize_random_images(images_dir=\"./output/images\", \n",
    "                            labels_dir=\"./output/labels\", \n",
    "                            num_images=5, \n",
    "                            max_display_size=720)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
