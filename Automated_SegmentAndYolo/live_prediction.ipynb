{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6960fbb5",
   "metadata": {},
   "source": [
    "### Live Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baec892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14b7109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Class-color mapping (same as yours)\n",
    "class_id_to_name = {\n",
    "    0:  ('road', [28, 42, 168]),\n",
    "    1:  ('pool', [0, 50, 89]),\n",
    "    2:  ('vegetation', [107, 142, 35]),\n",
    "    3:  ('roof', [70, 70, 70]),\n",
    "    4:  ('wall', [102, 102, 156]),\n",
    "    5:  ('window', [254, 228, 12]),\n",
    "    6:  ('person', [255, 22, 96]),\n",
    "    7:  ('dog', [102, 51, 0]),\n",
    "    8:  ('car', [9, 143, 150]),\n",
    "    9:  ('bicycle', [119, 11, 32]),\n",
    "    10: ('tree', [51, 51, 0]),\n",
    "    11: ('truck', [160, 160, 60]),\n",
    "    12: ('bus', [200, 80, 80]),\n",
    "    13: ('vehicle', [20, 80, 80]),\n",
    "}\n",
    "\n",
    "def load_model(model_path=\"best.pt\"):\n",
    "    return YOLO(model_path)\n",
    "\n",
    "def predict_frame(model, frame, conf_thresh=0.5, save_dir=None, frame_id=\"0000\"):\n",
    "    results = model.predict(source=frame, conf=conf_thresh, verbose=False)\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    # Prepare directories\n",
    "    if save_dir:\n",
    "        os.makedirs(f\"{save_dir}/images\", exist_ok=True)\n",
    "        os.makedirs(f\"{save_dir}/labels\", exist_ok=True)\n",
    "\n",
    "    label_lines = []\n",
    "    \n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            class_name, color = class_id_to_name.get(cls_id, (f\"class_{cls_id}\", [0, 255, 0]))\n",
    "            label = f\"{class_name}: {conf:.2f}\"\n",
    "\n",
    "            # Draw on image (annotation)\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(annotated, label, (x1, max(y1 - 10, 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            if save_dir:\n",
    "                # YOLO format: class_id x_center y_center width height (normalized)\n",
    "                h, w, _ = frame.shape\n",
    "                xc = (x1 + x2) / 2 / w\n",
    "                yc = (y1 + y2) / 2 / h\n",
    "                bw = (x2 - x1) / w\n",
    "                bh = (y2 - y1) / h\n",
    "                label_lines.append(f\"{cls_id} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "    if save_dir:\n",
    "        # Save original image (real image)\n",
    "        cv2.imwrite(f\"{save_dir}/images/frame_{frame_id}.jpg\", frame)\n",
    "        # Save annotated image\n",
    "        # cv2.imwrite(f\"{save_dir}/images/frame_{frame_id}_annotated.jpg\", annotated)\n",
    "        # Save label in YOLO format\n",
    "        with open(f\"{save_dir}/labels/frame_{frame_id}.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "    return annotated\n",
    "\n",
    "def run_webcam_detection(model_path=\"best.pt\", save=False):\n",
    "    model = load_model(model_path)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    save_dir = \"output\" if save else None\n",
    "    frame_count = 0\n",
    "\n",
    "    print(\"Press 'q' to exit...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id = f\"{frame_count:05d}\"\n",
    "        annotated_frame = predict_frame(model, frame, save_dir=save_dir, frame_id=frame_id)\n",
    "        cv2.imshow(\"YOLOv8 Live Detection\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ada6e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_dir='runs_yolo/'):\n",
    "    best_paths = list(Path(base_dir).rglob('best.pt'))\n",
    "    if not best_paths:\n",
    "        raise FileNotFoundError(\"No 'best.pt' file found in the 'runs/' directory.\")\n",
    "    \n",
    "    # Optionally, sort by latest modified time\n",
    "    best_paths.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    print(f\"✅ Found best.pt at: {best_paths[0]}\")\n",
    "    return str(best_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "378ea3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to draw bounding boxes from YOLO format labels\n",
    "def draw_bounding_boxes(image, label_path, class_id_to_name):\n",
    "    with open(label_path, \"r\") as file:\n",
    "        labels = file.readlines()\n",
    "\n",
    "    for label in labels:\n",
    "        parts = label.strip().split()\n",
    "        class_id = int(parts[0])\n",
    "        xc, yc, bw, bh = map(float, parts[1:])\n",
    "        \n",
    "        # Get the image dimensions\n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        # Convert YOLO format to pixel values\n",
    "        x1 = int((xc - bw / 2) * w)\n",
    "        y1 = int((yc - bh / 2) * h)\n",
    "        x2 = int((xc + bw / 2) * w)\n",
    "        y2 = int((yc + bh / 2) * h)\n",
    "\n",
    "        # Get class name and color\n",
    "        class_name, color = class_id_to_name.get(class_id, (f\"class_{class_id}\", [0, 255, 0]))\n",
    "\n",
    "        # Draw the bounding box and label\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, f\"{class_name}\", (x1, max(y1 - 10, 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "def visualize_random_images(images_dir=\"./datasets/split_videos_dataset/train/images\", \n",
    "                            labels_dir=\"./datasets/split_videos_dataset/train/labels\", \n",
    "                            num_images=10, \n",
    "                            max_display_size=800):\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "    random_images = random.sample(image_files, min(num_images, len(image_files)))\n",
    "\n",
    "    for image_file in random_images:\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        label_path = os.path.join(labels_dir, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: No label file found for {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Failed to read {image_path}\")\n",
    "            continue\n",
    "\n",
    "        print(\"Image:\", image_path)\n",
    "        image_with_boxes = draw_bounding_boxes(image, label_path, class_id_to_name)\n",
    "\n",
    "        # Resize image to fit screen\n",
    "        h, w = image_with_boxes.shape[:2]\n",
    "        scale = min(max_display_size / max(h, w), 1.0)\n",
    "        resized = cv2.resize(image_with_boxes, (int(w * scale), int(h * scale)))\n",
    "\n",
    "        # Display image\n",
    "        cv2.imshow(f\"Image: {image_file}\", resized)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17e7be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Class-color mapping (same as yours)\n",
    "class_id_to_name = {\n",
    "    0:  ('unlabeled', [28, 42, 168]),\n",
    "    1:  ('wall', [0, 50, 89]),\n",
    "    2:  ('vegetation', [107, 142, 35]),\n",
    "    3:  ('roof', [70, 70, 70]),\n",
    "    4:  ('wall', [102, 102, 156]),\n",
    "    5:  ('window', [254, 228, 12]),\n",
    "    6:  ('person', [255, 22, 96]),\n",
    "    7:  ('dog', [102, 51, 0]),\n",
    "    8:  ('car', [9, 143, 150]),\n",
    "    9:  ('bicycle', [119, 11, 32]),\n",
    "    10: ('tree', [51, 51, 0]),\n",
    "    11: ('truck', [160, 160, 60]),\n",
    "    12: ('bus', [200, 80, 80]),\n",
    "    13: ('vehicle', [20, 80, 80]),\n",
    "}\n",
    "\n",
    "def load_model(model_path=\"best.pt\"):\n",
    "    return YOLO(model_path)\n",
    "\n",
    "def predict_frame(model, frame, conf_thresh=0.3, save_dir=None, frame_id=\"0000\"):\n",
    "    results = model.predict(source=frame, conf=conf_thresh, verbose=False)\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    # Prepare directories\n",
    "    if save_dir:\n",
    "        os.makedirs(f\"{save_dir}/images\", exist_ok=True)\n",
    "        os.makedirs(f\"{save_dir}/labels\", exist_ok=True)\n",
    "\n",
    "    label_lines = []\n",
    "    \n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            class_name, color = class_id_to_name.get(cls_id, (f\"class_{cls_id}\", [0, 255, 0]))\n",
    "            label = f\"{class_name}: {conf:.2f}\"\n",
    "\n",
    "            # Draw on image (annotation)\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(annotated, label, (x1, max(y1 - 10, 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            if save_dir:\n",
    "                # YOLO format: class_id x_center y_center width height (normalized)\n",
    "                h, w, _ = frame.shape\n",
    "                xc = (x1 + x2) / 2 / w\n",
    "                yc = (y1 + y2) / 2 / h\n",
    "                bw = (x2 - x1) / w\n",
    "                bh = (y2 - y1) / h\n",
    "                label_lines.append(f\"{cls_id} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "    if save_dir:\n",
    "        # Save original image (real image)\n",
    "        cv2.imwrite(f\"{save_dir}/images/frame_{frame_id}.jpg\", frame)\n",
    "        # Save label in YOLO format\n",
    "        with open(f\"{save_dir}/labels/frame_{frame_id}.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "    return annotated\n",
    "\n",
    "def compare_two_models_live(model_a_path=\"best.pt\", model_b_path=\"best.pt\", save=False):\n",
    "    # Load two models\n",
    "    model_a = load_model(model_a_path)\n",
    "    model_b = load_model(model_b_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    save_dir = \"output\" if save else None\n",
    "    frame_count = 0\n",
    "\n",
    "    print(\"Press 'q' to exit...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id = f\"{frame_count:05d}\"\n",
    "\n",
    "        # Annotate frames using both models\n",
    "        left_frame = predict_frame(model_a, frame, save_dir=save_dir, frame_id=frame_id)\n",
    "        right_frame = predict_frame(model_b, frame, save_dir=save_dir, frame_id=frame_id)\n",
    "\n",
    "        # Resize frames to a consistent height while maintaining the aspect ratio\n",
    "        target_height = 420  # Target height for resizing\n",
    "        left_resized = resize_to_height(left_frame, target_height)\n",
    "        right_resized = resize_to_height(right_frame, target_height)\n",
    "\n",
    "        # Find the maximum width between the two resized frames to align them horizontally\n",
    "        combined_width = left_resized.shape[1] + right_resized.shape[1]\n",
    "        combined_frame = cv2.hconcat([left_resized, right_resized])\n",
    "\n",
    "        # Display the combined output of both models\n",
    "        cv2.imshow(\"Compare: Model A (Left) vs Model B (Right)\", combined_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def resize_to_height(image, target_height=420):\n",
    "    \"\"\"\n",
    "    Resize image while maintaining aspect ratio.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    scale = target_height / h\n",
    "    new_w = int(w * scale)\n",
    "    return cv2.resize(image, (new_w, target_height))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c8bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091e041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd27ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ca837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8bd457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50e76f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# def check_cameras():\n",
    "#     # Try accessing different camera indices, typically 0 is the default (laptop camera)\n",
    "#     for i in range(5):  # You can increase the range if you have more cameras\n",
    "#         cap = cv2.VideoCapture(i)\n",
    "#         if cap.isOpened():\n",
    "#             print(f\"Camera {i} is accessible.\")\n",
    "#             ret, frame = cap.read()\n",
    "#             if ret:\n",
    "#                 print(f\"Camera {i} is showing a frame.\")\n",
    "#                 cv2.imshow(f\"Camera {i}\", frame)\n",
    "#                 cv2.waitKey(0)  # Wait for any key to close the window\n",
    "#             cap.release()\n",
    "#         else:\n",
    "#             print(f\"Camera {i} is not accessible.\")\n",
    "\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Call the function to check for cameras\n",
    "# check_cameras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b676d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found best.pt at: runs\\train\\yolov8\\weights\\best.pt\n",
      "✅ Found best.pt at: runs\\train\\fine-tune-yolov8\\weights\\best.pt\n",
      "Press 'q' to exit...\n"
     ]
    }
   ],
   "source": [
    "yolov8 = './runs/train/yolov8'\n",
    "yolov8_retrain = './runs/train/fine-tune-yolov8'\n",
    "\n",
    "best_pt_path = find_best_model(yolov8)\n",
    "best_pt_path_retrain = find_best_model(yolov8_retrain)\n",
    "\n",
    "# run_webcam_detection(best_pt_path, True)\n",
    "\n",
    "# Run webcam detection with two models\n",
    "compare_two_models_live(model_a_path=best_pt_path, model_b_path=best_pt_path_retrain, save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8df9d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Function to visualize random images and bounding boxes\n",
    "# visualize_random_images(images_dir=\"./datasets/split_videos_dataset/train/images\", \n",
    "#                             labels_dir=\"./datasets/split_videos_dataset/train/labels\", \n",
    "#                             num_images=20, \n",
    "#                             max_display_size=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cae537a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All images have corresponding labels and vice versa!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_image_label_correspondence(images_dir, labels_dir, image_exts={'.jpg', '.png'}, label_ext='.txt'):\n",
    "    image_files = [f for f in os.listdir(images_dir) if os.path.splitext(f)[1].lower() in image_exts]\n",
    "    label_files = [f for f in os.listdir(labels_dir) if f.endswith(label_ext)]\n",
    "\n",
    "    image_basenames = set(os.path.splitext(f)[0] for f in image_files)\n",
    "    label_basenames = set(os.path.splitext(f)[0] for f in label_files)\n",
    "\n",
    "    missing_labels = image_basenames - label_basenames\n",
    "    missing_images = label_basenames - image_basenames\n",
    "\n",
    "    if missing_labels:\n",
    "        print(\"❌ Missing labels for the following images:\")\n",
    "        for name in sorted(missing_labels):\n",
    "            print(f\"- {name}\")\n",
    "\n",
    "    if missing_images:\n",
    "        print(\"❌ Missing images for the following labels:\")\n",
    "        for name in sorted(missing_images):\n",
    "            print(f\"- {name}\")\n",
    "\n",
    "    if not missing_labels and not missing_images:\n",
    "        print(\"✅ All images have corresponding labels and vice versa!\")\n",
    "\n",
    "# ======== Example usage ========\n",
    "images_path = \"./datasets/split_videos_dataset/train/images\"\n",
    "labels_path = \"./datasets/split_videos_dataset/train/labels\"\n",
    "check_image_label_correspondence(images_path, labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a9045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25833ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5c16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
