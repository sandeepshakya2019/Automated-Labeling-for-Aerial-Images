{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d60422e",
   "metadata": {},
   "source": [
    "### Class ID to Name Mapping with RGB Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf99f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_to_name = {\n",
    "    0:  ('road', [28, 42, 168]),\n",
    "    1:  ('pool', [0, 50, 89]),\n",
    "    2:  ('vegetation', [107, 142, 35]),\n",
    "    3:  ('roof', [70, 70, 70]),\n",
    "    4:  ('wall', [102, 102, 156]),\n",
    "    5:  ('window', [254, 228, 12]),\n",
    "    6:  ('person', [255, 22, 96]),\n",
    "    7:  ('dog', [102, 51, 0]),\n",
    "    8:  ('car', [9, 143, 150]),\n",
    "    9:  ('bicycle', [119, 11, 32]),\n",
    "    10: ('tree', [51, 51, 0]),\n",
    "    11: ('truck', [160, 160, 60]),   # added truck\n",
    "    12: ('bus', [200, 80, 80]),      # added bus\n",
    "    13: ('vehicle', [20, 80, 80]),      # added bus\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab9894",
   "metadata": {},
   "source": [
    "### Comparing YOLO Model Predictions on Video: Original vs Fine-Tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "513f6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def annotate_frame(frame, model, class_id_to_name, conf=0.25):\n",
    "    \"\"\"\n",
    "    Annotates the frame with predictions from the model.\n",
    "    \"\"\"\n",
    "    annotated = frame.copy()\n",
    "    results = model(annotated, conf=conf, verbose=False)[0]\n",
    "\n",
    "    if results.boxes is None or results.boxes.xyxy is None:\n",
    "        return annotated  # No detections\n",
    "\n",
    "    boxes = results.boxes.xyxy.cpu().numpy()\n",
    "    class_ids = results.boxes.cls.cpu().numpy()\n",
    "    confidences = results.boxes.conf.cpu().numpy()\n",
    "\n",
    "    # Debugging: Print the number of detections and confidences\n",
    "    # print(f\"Model {model} detected {len(boxes)} boxes\")\n",
    "    # print(f\"Confidences {model}: {confidences}\")\n",
    "\n",
    "    for box, cls_id, confidence in zip(boxes, class_ids, confidences):\n",
    "        if confidence < conf:\n",
    "            continue  # Skip detections below the confidence threshold\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        class_name, color = class_id_to_name.get(int(cls_id), (f\"id:{int(cls_id)}\", (0, 255, 255)))\n",
    "        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(annotated, f\"{class_name} {confidence:.2f}\", (x1, max(y1 - 10, 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    return annotated\n",
    "\n",
    "def resize_to_height(image, target_height=420):\n",
    "    \"\"\"\n",
    "    Resize image while maintaining aspect ratio.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    scale = target_height / h\n",
    "    new_w = int(w * scale)\n",
    "    return cv2.resize(image, (new_w, target_height))\n",
    "\n",
    "def compare_models_live(video_path, model_a_path, model_b_path, class_id_to_name, conf=0.25):\n",
    "    \"\"\"\n",
    "    Compare the predictions of two models (Model A and Model B) on a video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"❌ Failed to open video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    model_a = YOLO(model_a_path)\n",
    "    model_b = YOLO(model_b_path)\n",
    "\n",
    "    print(\"[INFO] Press 'q' to quit, 'p' to pause, 'r' to resume.\")\n",
    "    paused = False  # Variable to keep track of the pause state\n",
    "\n",
    "    while True:\n",
    "        if not paused:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"[INFO] End of video or failed to read frame.\")\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                # Annotate frames using both models\n",
    "                left = annotate_frame(frame, model_a, class_id_to_name, conf)\n",
    "                right = annotate_frame(frame, model_b, class_id_to_name, conf)\n",
    "\n",
    "                # Resize frames to a consistent height while maintaining the aspect ratio\n",
    "                target_height = 420  # Target height for resizing\n",
    "                left_resized = resize_to_height(left, target_height)\n",
    "                right_resized = resize_to_height(right, target_height)\n",
    "\n",
    "                # Find the maximum width between the two resized frames to align them horizontally\n",
    "                combined_width = left_resized.shape[1] + right_resized.shape[1]\n",
    "                combined = cv2.hconcat([left_resized, right_resized])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error during frame processing: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Display the combined output of both models\n",
    "            cv2.imshow(\"Compare: Fine-Tuned (Left) vs Original (Right)\", combined)\n",
    "\n",
    "        # Key press handling\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # 'q' to quit\n",
    "            break\n",
    "        elif key == ord('p'):  # 'p' to pause\n",
    "            paused = True\n",
    "            print(\"[INFO] Paused. Press 'r' to resume.\")\n",
    "        elif key == ord('r'):  # 'r' to resume\n",
    "            paused = False\n",
    "            print(\"[INFO] Resumed.\")\n",
    "\n",
    "        # Ensure 'q' can still quit the program even if paused\n",
    "        if paused:\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):  # 'q' to quit\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a7ecf",
   "metadata": {},
   "source": [
    "### Find Best YOLO Model: Searching for 'best.pt' in Training Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d448713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_best_model(base_dir='runs_yolo/'):\n",
    "    best_paths = list(Path(base_dir).rglob('best.pt'))\n",
    "    if not best_paths:\n",
    "        raise FileNotFoundError(\"No 'best.pt' file found in the 'runs/' directory.\")\n",
    "    \n",
    "    # Optionally, sort by latest modified time\n",
    "    best_paths.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    print(f\"✅ Found best.pt at: {best_paths[0]}\")\n",
    "    return str(best_paths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64d4be",
   "metadata": {},
   "source": [
    "## Comparing YOLO Models: Pretrained vs Fine-Tuned on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9aa31615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found best.pt at: runs\\train\\yolov8\\weights\\best.pt\n",
      "✅ Found best.pt at: runs\\train\\fine-tune-yolov8\\weights\\best.pt\n",
      "[INFO] Press 'q' to quit, 'p' to pause, 'r' to resume.\n"
     ]
    }
   ],
   "source": [
    "new_path = './runs/train/fine-tune-yolov8'\n",
    "old_path = './runs/train/yolov8'\n",
    "\n",
    "best_pt_path = find_best_model(old_path)\n",
    "best_pt_path_retrain = find_best_model(new_path)\n",
    "\n",
    "\n",
    "compare_models_live(\n",
    "    video_path=\"./a/v1.mp4\",\n",
    "    model_a_path=best_pt_path,  # Pretrained model\n",
    "    model_b_path=best_pt_path_retrain,  # Fine-tuned model\n",
    "    class_id_to_name=class_id_to_name,\n",
    "    conf=0.6\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
